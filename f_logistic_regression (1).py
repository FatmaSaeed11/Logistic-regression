# -*- coding: utf-8 -*-
"""F logistic regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AsJHI9ZVrWzcvu2lepkOdFV0grt382sL
"""

#import libraries
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import classification_report
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from sklearn.metrics import zero_one_loss

#import data
data_train_load=pd.read_csv('/content/mobile/train.csv')
data_test_load=pd.read_csv('/content/mobile/test.csv')
data_train_load.head(2100)

data_test_load.head(1100)

#normalization
data_train=data_train_load.drop("price_range",axis="columns")
data_test=data_test_load.drop("id",axis="columns")

data_train

data_test

Y=data_train_load['price_range']

#scaling

sc=StandardScaler()
data_train_s=sc.fit_transform(data_train_load)
data_test_s=sc.transform(data_test_load)

data_train

data_test

#logistic regression fit,score
model=LogisticRegression()
model.fit(data_train_s,Y)

#predict
Y_pred=model.predict(data_test_s)

#split data again

data_train_load,data_test_load,Y_train,Y_test=train_test_split(data_train,Y,test_size=0.2,random_state=12)

#normalization again
sc=StandardScaler()
data_train_ss=sc.fit_transform(data_train_load)
data_test_ss=sc.transform(data_test_load)

#logistic regression fit,score again
model=LogisticRegression()
model.fit(data_train_ss,Y_train)

#predict
Y_pred=model.predict(data_test_ss)
#accuracy
accuracy_score(Y_test,Y_pred)

#know num of iteration, classes
n=model.n_iter_
print(n)
x=model.classes_
print(x)
#probability
pr=model.predict_proba(data_test_load)
print(pr)

#confusion matrix
from sklearn.metrics import confusion_matrix
cm=confusion_matrix(Y_test,Y_pred)
print(cm)

from sklearn.metrics import mean_absolute_error
absolute=mean_absolute_error(Y_test,Y_pred)
print(absolute)

from sklearn.metrics import mean_squared_error
squared=mean_squared_error(Y_test,Y_pred)
print(squared)

from sklearn.metrics import median_absolute_error
med=mean_squared_error(Y_test,Y_pred)
print(med)

sensitivity=recall_score(Y_test,Y_pred,average='macro')
print(sensitivity)

specificity=recall_score(np.logical_not(Y_test),np.logical_not(Y_pred),average='macro')
print(specificity)

precision_score_result=precision_score(Y_test,Y_pred,average='macro')
print(precision_score_result)

recall_score_result=recall_score(Y_test,Y_pred,average='macro')
print(recall_score_result)

# ROC Curve
fpr, tpr, thresholds = roc_curve(Y_test, Y_pred ,pos_label=1)

plt.figure(figsize=(6,4))

plt.plot(fpr, tpr, linewidth=2)

plt.plot([0,1], [0,1], 'k--' )

plt.rcParams['font.size'] = 12

plt.title('ROC curve for Predicting a Pulsar Star classifier')

plt.xlabel('False Positive Rate (1 - Specificity)')

plt.ylabel('True Positive Rate (Sensitivity)')

plt.show()